{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Donald-Tweets!.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../Donald Twitter Generation/input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7375, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Tweet_Text</th>\n",
       "      <th>Type</th>\n",
       "      <th>Media_Type</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Tweet_Url</th>\n",
       "      <th>twt_favourites_IS_THIS_LIKE_QUESTION_MARK</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>15:26:37</td>\n",
       "      <td>Today we express our deepest gratitude to all ...</td>\n",
       "      <td>text</td>\n",
       "      <td>photo</td>\n",
       "      <td>ThankAVet</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>127213</td>\n",
       "      <td>41112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>13:33:35</td>\n",
       "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>141527</td>\n",
       "      <td>28654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>11:14:20</td>\n",
       "      <td>Love the fact that the small groups of protest...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>183729</td>\n",
       "      <td>50039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>2:19:44</td>\n",
       "      <td>Just had a very open and successful presidenti...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>214001</td>\n",
       "      <td>67010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>2:10:46</td>\n",
       "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>178499</td>\n",
       "      <td>36688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Time                                         Tweet_Text  \\\n",
       "0  16-11-11  15:26:37  Today we express our deepest gratitude to all ...   \n",
       "1  16-11-11  13:33:35  Busy day planned in New York. Will soon be mak...   \n",
       "2  16-11-11  11:14:20  Love the fact that the small groups of protest...   \n",
       "3  16-11-11   2:19:44  Just had a very open and successful presidenti...   \n",
       "4  16-11-11   2:10:46  A fantastic day in D.C. Met with President Oba...   \n",
       "\n",
       "   Type Media_Type   Hashtags      Tweet_Id  \\\n",
       "0  text      photo  ThankAVet  7.970000e+17   \n",
       "1  text        NaN        NaN  7.970000e+17   \n",
       "2  text        NaN        NaN  7.970000e+17   \n",
       "3  text        NaN        NaN  7.970000e+17   \n",
       "4  text        NaN        NaN  7.970000e+17   \n",
       "\n",
       "                                           Tweet_Url  \\\n",
       "0  https://twitter.com/realDonaldTrump/status/797...   \n",
       "1  https://twitter.com/realDonaldTrump/status/797...   \n",
       "2  https://twitter.com/realDonaldTrump/status/797...   \n",
       "3  https://twitter.com/realDonaldTrump/status/796...   \n",
       "4  https://twitter.com/realDonaldTrump/status/796...   \n",
       "\n",
       "   twt_favourites_IS_THIS_LIKE_QUESTION_MARK  Retweets  Unnamed: 10  \\\n",
       "0                                     127213     41112          NaN   \n",
       "1                                     141527     28654          NaN   \n",
       "2                                     183729     50039          NaN   \n",
       "3                                     214001     67010          NaN   \n",
       "4                                     178499     36688          NaN   \n",
       "\n",
       "   Unnamed: 11  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "df = pd.read_csv('../Donald Twitter Generation/input/Donald-Tweets!.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase all\n",
    "text = df['Tweet_Text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we probably want to keep the hashtags, but if there are for example random characters (like links), we want to drop them so they won't affct the precictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i will be on @meetthepress in an interview with @chucktodd on sunday morning. so much to talk about!',\n",
       "       '\"minorities line up behind donald trump\" #trump2016\\nhttps://t.co/clcvogwomy',\n",
       "       'make america great again!\\n#inprimary #votetrump\\nhttps://t.co/nmqekxccv6',\n",
       "       'thank you for all of your support iowa!\\n#makeamericagreatagain #trump2016\\n#iacaucus finder: https://t.co/anvtczqfoq https://t.co/fqaxume01b',\n",
       "       '\"every american needs to say 2 simple words to every vet they meet: thank you!\" john wayne walding\\nhttps://t.co/wg8ezphzt1',\n",
       "       'a suicide bomber has just killed u.s. troops in afghanistan. when will our leaders get tough and smart. we are being led to slaughter!',\n",
       "       'thank you, new hampshire! great people -- see you next week! https://t.co/r83xq8kxp5',\n",
       "       'during primetime of the iowa caucus, cruz put out a release that @realbencarson was quitting the race, and to caucus (or vote) for cruz.',\n",
       "       'thank you tennessee! #maga https://t.co/oodfmerq5b',\n",
       "       'rt @anncoulter: .@realdonaldtrump leads w/ hispanics. huckabee &amp; christie - who supported in-state tuition 4 illegals -scrape bottom. http:_'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "np.random.choice(text,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:\n",
      "today we express our deepest gratitude to all those who have served in our armed forces. #thankavet https://t.co/wpk7qwpk8z\n",
      "AFTER:\n",
      "today we express our deepest gratitude to all those who have served in our armed forces. #thankavet\n"
     ]
    }
   ],
   "source": [
    "print('BEFORE:')\n",
    "print(text[0])\n",
    "text = text.map(lambda s: ' '.join([x for x in s.split() if 'http' not in x]))\n",
    "print('AFTER:')\n",
    "print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "any super short tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tweet len: 151\n",
      "min tweet len: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e58dd22f60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('max tweet len:',text.map(len).max())\n",
    "print('min tweet len:',text.map(len).min())\n",
    "text.map(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6366"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text[text.map(len)>60]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Chars Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 78\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(text))))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '=',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " 'ʉ',\n",
       " '̱',\n",
       " 'ω',\n",
       " 'я',\n",
       " 'ӕ',\n",
       " 'ԍ',\n",
       " 'ԏ',\n",
       " 'ԡ',\n",
       " 'լ',\n",
       " 'ջ',\n",
       " 'ُ',\n",
       " '٪',\n",
       " '\\u06dd',\n",
       " 'ۢ',\n",
       " '۪']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe last ones are emojis?\n",
    "Let's take a look at sentences with the weird chars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHAR: {\n",
      "['\"{crooked hillary clinton} created this mess, and she knows it.\" #draintheswamp']\n",
      "\n",
      "CHAR: |\n",
      "['join me in florida on wednesday! daytona &amp; jacksonville: daytona | 3pm- jacksonville | 7pm-', '\"@politico: palin on 2016: \"i think it would come down to cruz and trump! | getty', 'rt @danscavino: 2016 gop primary hp tracking 139 polls | 28 pollsters. #1 trump 24.1% #2 bush 10.7% #3 carson 8.6% #4 rubio 6.8%']\n",
      "\n",
      "CHAR: }\n",
      "['\"{crooked hillary clinton} created this mess, and she knows it.\" #draintheswamp']\n",
      "\n",
      "CHAR: ~\n",
      "['\"@destiny: why didnt @seanhannity correct jeb when he said @realdonaldtrump has run 4 president 2x b4~jeb needs 2b corrected b/c he lied.\"', 'join me in roanoke, virginia tomorrow at the berglund center- coliseum ~ 6pm! tickets available at:_', '\"@freestateyank: \"the only way anybodys gonna beat trump is being better than he is.\"~@rushlimbaugh on @realdonaldtrump.\"']\n",
      "\n",
      "CHAR: ʉ\n",
      "['my pro-growth econ plan: eliminate excessive regulations! lean government! lower taxes! #debatesʉ_']\n",
      "\n",
      "CHAR: ̱\n",
      "['mexico has lost a brilliant finance minister and wonderful man who i know is highly respected by president pe̱a nieto.']\n",
      "\n",
      "CHAR: ω\n",
      "['via @breitbartnews by steve bannon: ωtime to get tough۪: trump۪s blockbuster policy manifesto\\u06dd']\n",
      "\n",
      "CHAR: я\n",
      "['\"@tn_riverfolk: my 2016 vote will b based on #makeamericagreatagain not eminent domainяamericans need 2prioritize']\n",
      "\n",
      "CHAR: ӕ\n",
      "['fact ӕ on red line\\u06dd in syria: hrc \"i wasn۪t there.\" fact: line drawn in aug ۪12. hrc secy of state til feb ۪13.', 'rt @teamtrump: #rattledhillary wants to talk about her 30 years in service. how about her 30 years of flopsӕflops?! #bigleaguetruth #debat_']\n",
      "\n",
      "CHAR: ԍ\n",
      "['rt @linflies: @realdonaldtrump beautiful family! best man for #potus ! _ԍ_ُ___', '\"@bentleyfortrump: @realdonaldtrump all of america loves trump!_ԍ_ԍ #trumpornobody2016 #makeamericagreatagain\" thank you.', '\"@dboiarsky: @realdonaldtrump make america great again, dt! _ԍ\"']\n",
      "\n",
      "CHAR: ԏ\n",
      "['\"@repalonelori: @realdonaldtrump @kirstiealley we love you and know you will do an awesome job! saw you in bethpage !! _ԏ_ԏ_ԏ\" thank you.']\n",
      "\n",
      "CHAR: ԡ\n",
      "['\"@good2bqueen67: .@realdonaldtrump @sandikay60 i enjoyed the speech so much tonight, you were on point _ԡ sir!\" thanks.']\n",
      "\n",
      "CHAR: լ\n",
      "['rt @erictrump: #wisconsin: to find your voting location visit #makeamericagreatagain #trumptrain ___լ_լ______']\n",
      "\n",
      "CHAR: ջ\n",
      "['rt @darrenjjordan: constructive wins! _ջ @realdonaldtrump @clewandowski_ @danscavino @michaelcohen212 @katrinapierson @defendingtheusa']\n",
      "\n",
      "CHAR: ُ\n",
      "['\"@hbtc23: @realdonaldtrump backs down from nobody!! #makeamericagreatagain #trump2016 @steveaustinbsr @wwe __ _٪_ُ', '\"@plruble58 @realdonaldtrump the numbers are amazing! #gogogo_ُ\"', '\"@trumpsmyhomeboy: @realdonaldtrump @robostop10 @politico the #msm straw man candidate is falling apart!___ُ_\"']\n",
      "\n",
      "CHAR: ٪\n",
      "['\"@hbtc23: @realdonaldtrump backs down from nobody!! #makeamericagreatagain #trump2016 @steveaustinbsr @wwe __ _٪_ُ']\n",
      "\n",
      "CHAR: ۝\n",
      "['.@gerardtbaker gerardwonderful job last night as moderator of the debate. i told many, really smart and elegant.\\u06dd', 'hypocrite! @hillaryclinton claims she needs a public and a private stance\\u06dd in discussions with wall street banks. #debate', '\"@iliveamongyou: urgent @gop_in an effort to destroy their own front runner.\\u06dd #makeamericagreatagain i hit back!']\n",
      "\n",
      "CHAR: ۢ\n",
      "['rt @danscavino: great poll #news from #alabama!! @realdonaldtrump #1 ۢ with a lead 2xs higher than #2 jeb bush. #trump2016__', 'rt @danscavino: \"do not underestimate the power of @realdonaldtrump ۢ he will sweep down &amp; get that gop nomination!\" @omarosa on @cnn w/ @d_', 'rt @danscavino: #breaking #abc #news ۢ #washington, releases poll @ 5pet with @realdonaldtrump at 24% &amp; 2nd place coming in at 13%...']\n",
      "\n",
      "CHAR: ۪\n",
      "['what they are saying about the clinton campaign۪s anti-catholic bigotry:', 'flashback donald trump blasts obama for failing to secure christian pastor۪s freedom in iran\" via @theblaze۪', '\"@gpavlik7 1/2 of new california driver۪s licenses go to undocumented immigrants. read the sac bee, july 17th. go getem, trump!\"']\n"
     ]
    }
   ],
   "source": [
    "for c in chars[-19:]:\n",
    "    print('\\nCHAR:', c)\n",
    "    smple = [x for x in text if c in x]\n",
    "    print(random.sample(smple,min(3,len(smple))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still weird....\n",
    "let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for c in chars[-19:]:\n",
    "    text = text.str.replace(c,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '=',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(text))))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input Data\n",
    "<br>\n",
    "input - 40 characters of a tweet\n",
    "<br>\n",
    "output - next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 472774\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for x in text:\n",
    "    for i in range(0, len(x) - maxlen, step):\n",
    "        sentences.append(x[i: i + maxlen])\n",
    "        next_chars.append(x[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today we express our deepest gratitude t ==> o\n",
      "oday we express our deepest gratitude to ==>  \n",
      "day we express our deepest gratitude to  ==> a\n"
     ]
    }
   ],
   "source": [
    "## check example\n",
    "for i in range(3):\n",
    "    print(sentences[i],'==>',next_chars[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'today we express our deepest gratitude to all those who have served in our armed forces. #thankavet'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "1. Turn X into matrix of (numer_of_sentences,max_len_of_sentence,num_chars).\n",
    "<br>\n",
    "If char i is number j char in sentence k, there will be a 1 in location (k,j,i)\n",
    "<br>\n",
    "2. Turn y into a vector of (number_of_sentences,num_chars).\n",
    "<br>\n",
    "If character z is the next character in sentence k, there will be a 1 in locaiton (k,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the model: a single LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define we have a sequential model\n",
    "2. Add an LSTM layer with 128 units. Input shape is a matrix of maxlen characters, where each character is a vector of len(chars)\n",
    "3. Add a dense layer (fully connected layer) and have the softmax activation pick a winner from the len(chars) possible characters.\n",
    "4. Pick an optimizer for the network and choose categorical_crossentropy loss function (used in multiclass classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DESKTOP-72444VQ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DESKTOP-72444VQ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DESKTOP-72444VQ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DESKTOP-72444VQ\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DESKTOP-72444VQ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# optimizer = RMSprop(lr=0.01)\n",
    "optimizer = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler\n",
    "We don't want the next character to be the one with the highest probaility (we'll get the same results every time).\n",
    "So we sample with temperature parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example of what the function does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for temperature in [0.1, 0.2, 0.3,  0.5, 1.0, 1.2, 1.3]:\n",
    "    print(sample([.1,.3,.5,.1],temperature=temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gave the function an array where highest probability was index number 2 (.5).\n",
    "When temperature was low, we got what we expected.\n",
    "As we increased the temperature, the function got more creative license choosing the max.\n",
    "So:\n",
    "1. temperature helps us not get the same text generated every time\n",
    "2. low temperature = text similar to trained data\n",
    "3. high temperature = more creative generation\n",
    "4. too high temperature = nonsense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text at Epoch End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "#     start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    tweet = np.random.choice(text) # select random tweet\n",
    "    start_index = 0\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = tweet[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(120):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator.DESKTOP-72444VQ\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DESKTOP-72444VQ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/5\n",
      "472774/472774 [==============================] - 398s 841us/step - loss: 2.3545\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"the press has very inaccurately covered \"\n",
      "the press has very inaccurately covered the whe hes and the reald the wall the reald not the reald the reald and the the reald the wall the reald the realdont t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"the press has very inaccurately covered \"\n",
      "the press has very inaccurately covered deally the heper the not the cand be the realdont trump the reate a dong to make mericangreat again @trunghentathat and \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"the press has very inaccurately covered \"\n",
      "the press has very inaccurately covered nillly. thevecice #meic@ter.hinu2_\" fain elly out us ybe nogs yout 21%.!! #saby2_e1620y%\" 2\" no sur sub arestatis. ngrey\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"the press has very inaccurately covered \"\n",
      "the press has very inaccurately covered nigse colly than: sere iallaibated redeldoncwevstisnterunt in tham ke, sa dellas str.pelisig. cu. tr mppry atlo\", dica c\n",
      "Epoch 2/5\n",
      "472774/472774 [==============================] - 776s 2ms/step - loss: 1.9191\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"wow, did you just hear bill clintons sta\"\n",
      "wow, did you just hear bill clintons state so the will the real and the trump will be the cruz on the will be the will be a wand to the president and the wersen\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"wow, did you just hear bill clintons sta\"\n",
      "wow, did you just hear bill clintons stat in the mast the promes on cond to prosing just to he is the wast negute realys the way whe way. is a trump his beet ou\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"wow, did you just hear bill clintons sta\"\n",
      "wow, did you just hear bill clintons stajey to i sout dilloren you. refout a coorratet. erecinisy @con gaz is fir wosan ho wad a captaina. mineafor anowiow they\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"wow, did you just hear bill clintons sta\"\n",
      "wow, did you just hear bill clintons stated of mike hall puch. #going mack dinghirat.\".ht tomad trayy and a cam gree. haw bean leag. the_rin-tacsn erenebly e ju\n",
      "Epoch 3/5\n",
      "402432/472774 [========================>.....] - ETA: 10:13 - loss: 1.7752"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1582c3bc6cc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m           callbacks=[print_callback])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DESKTOP-72444VQ\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(128, input_shape=(maxlen, len(chars)),return_sequences=True))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(LSTM(128))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "# optimizer = RMSprop(lr=0.01)\n",
    "optimizer = Adam()\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375424/472774 [======================>.......] - ETA: 10:10 - loss: 2.4233"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model2.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
